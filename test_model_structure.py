#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦è…³æœ¬ï¼šæª¢æŸ¥æ¨¡å‹çµæ§‹å’Œ checkpoint å…§å®¹
"""

import torch
from pathlib import Path
import json

def inspect_checkpoint(model_path):
    """æª¢æŸ¥ checkpoint çš„è©³ç´°çµæ§‹"""
    print(f"\n{'='*80}")
    print(f"æª¢æŸ¥: {model_path.name}")
    print(f"{'='*80}")
    
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        
        print(f"\nâœ“ æˆåŠŸè¼‰å…¥ checkpoint")
        print(f"\nğŸ“‹ Checkpoint åŒ…å«çš„éµ:")
        
        # åˆ†é¡é¡¯ç¤º
        lstm_keys = {}
        regressor_keys = {}
        other_keys = {}
        
        for key in sorted(checkpoint.keys()):
            value = checkpoint[key]
            shape = value.shape if isinstance(value, torch.Tensor) else type(value)
            
            if 'lstm' in key:
                lstm_keys[key] = shape
            elif 'regressor' in key:
                regressor_keys[key] = shape
            else:
                other_keys[key] = shape
        
        # é¡¯ç¤º LSTM å±¤
        if lstm_keys:
            print(f"\nğŸ”¹ LSTM å±¤ ({len(lstm_keys)} å€‹):")
            for key, shape in sorted(lstm_keys.items()):
                print(f"  {key}: {shape}")
        
        # é¡¯ç¤º Regressor å±¤
        if regressor_keys:
            print(f"\nğŸ”¹ Regressor å±¤ ({len(regressor_keys)} å€‹):")
            for key, shape in sorted(regressor_keys.items()):
                print(f"  {key}: {shape}")
        
        # é¡¯ç¤ºå…¶ä»–
        if other_keys:
            print(f"\nğŸ”¹ å…¶ä»– ({len(other_keys)} å€‹):")
            for key, shape in sorted(other_keys.items()):
                print(f"  {key}: {shape}")
        
        # çµ±è¨ˆè³‡è¨Š
        print(f"\nğŸ“Š çµ±è¨ˆ:")
        print(f"  LSTM å±¤: {len(lstm_keys)} å€‹éµ")
        print(f"  Regressor å±¤: {len(regressor_keys)} å€‹éµ")
        print(f"  ç¸½è¨ˆ: {len(checkpoint)} å€‹éµ")
        
        # åˆ†æ LSTM çµæ§‹
        print(f"\nğŸ”¬ LSTM çµæ§‹åˆ†æ:")
        bidirectional = any('reverse' in k for k in lstm_keys.keys())
        print(f"  Bidirectional: {bidirectional}")
        
        # å¾ weight_ih_l0 æ¨æ–·è¼¸å…¥å¤§å°
        if 'lstm.weight_ih_l0' in lstm_keys:
            weight_ih_shape = lstm_keys['lstm.weight_ih_l0']
            # weight_ih çš„å½¢ç‹€æ˜¯ (gates * hidden_size, input_size)
            # gates = 4 (input, forget, cell, output)
            gates = 4
            hidden_size = weight_ih_shape[0] // gates
            input_size = weight_ih_shape[1]
            print(f"  Hidden size: {hidden_size}")
            print(f"  Input size: {input_size}")
            print(f"  Weight_ih shape: {weight_ih_shape}")
        
        # åˆ†æ Regressor çµæ§‹
        print(f"\nğŸ”¬ Regressor çµæ§‹åˆ†æ:")
        regressor_indices = []
        for key in regressor_keys.keys():
            # æå–å±¤ç´¢å¼•: regressor.0.weight -> 0
            parts = key.split('.')
            if len(parts) >= 2:
                try:
                    idx = int(parts[1])
                    if idx not in regressor_indices:
                        regressor_indices.append(idx)
                except:
                    pass
        
        regressor_indices.sort()
        print(f"  æœ‰åƒæ•¸çš„å±¤ç´¢å¼•: {regressor_indices}")
        
        # æ¨æ–·å±¤çµæ§‹
        if regressor_indices:
            print(f"  å±¤çµæ§‹ (æ¨æ¸¬):")
            for i, idx in enumerate(regressor_indices):
                if f'regressor.{idx}.weight' in regressor_keys:
                    weight_shape = regressor_keys[f'regressor.{idx}.weight']
                    print(f"    å±¤ {idx}: Linear{weight_shape}")
        
        return checkpoint, lstm_keys, regressor_keys
    
    except Exception as e:
        print(f"âœ— éŒ¯èª¤: {e}")
        return None, None, None


def test_model_loading(checkpoint_path, checkpoint_data):
    """æ¸¬è©¦æ¨¡å‹è¼‰å…¥"""
    print(f"\n{'='*80}")
    print(f"æ¸¬è©¦æ¨¡å‹è¼‰å…¥")
    print(f"{'='*80}\n")
    
    # å¾ checkpoint æ¨æ–·æ¨¡å‹åƒæ•¸
    lstm_keys = {k: v for k, v in checkpoint_data.items() if 'lstm' in k}
    regressor_keys = {k: v for k, v in checkpoint_data.items() if 'regressor' in k}
    
    # æ¨æ–· LSTM åƒæ•¸
    if 'lstm.weight_ih_l0' in lstm_keys:
        weight_ih_shape = lstm_keys['lstm.weight_ih_l0']
        hidden_size = weight_ih_shape[0] // 4
        input_size = weight_ih_shape[1]
    else:
        print("âœ— æ‰¾ä¸åˆ° lstm.weight_ih_l0")
        return
    
    # æ¨æ–· Regressor åƒæ•¸
    regressor_indices = set()
    for key in regressor_keys.keys():
        parts = key.split('.')
        if len(parts) >= 2:
            try:
                idx = int(parts[1])
                regressor_indices.add(idx)
            except:
                pass
    
    print(f"æ¨æ–·çš„æ¨¡å‹åƒæ•¸:")
    print(f"  Input size: {input_size}")
    print(f"  Hidden size: {hidden_size}")
    print(f"  Regressor å±¤ç´¢å¼•: {sorted(regressor_indices)}")
    
    # å˜—è©¦ä¸åŒçš„æ¨¡å‹çµæ§‹
    print(f"\nå˜—è©¦æ¨¡å‹çµæ§‹...\n")
    
    # æ–¹æ¡ˆ 1: ç°¡å–® Sequential
    print("æ–¹æ¡ˆ 1: ç°¡å–® Sequential (å±¤ç´¢å¼• 0-5)")
    try:
        model1 = torch.nn.Sequential(
            torch.nn.Linear(hidden_size * 2, 64),
            torch.nn.ReLU(),
            torch.nn.Dropout(0.2),
            torch.nn.Linear(64, 32),
            torch.nn.ReLU(),
            torch.nn.Linear(32, 1)
        )
        # æª¢æŸ¥ regressor state dict
        regressor_state = {k: v for k, v in checkpoint_data.items() if 'regressor' in k}
        missing = set(regressor_state.keys()) - set(f'regressor.{k}' for k in model1.state_dict().keys())
        unexpected = set(f'regressor.{k}' for k in model1.state_dict().keys()) - set(regressor_state.keys())
        
        if missing or unexpected:
            print(f"  âœ— ä¸åŒ¹é…")
            if missing:
                print(f"    ç¼ºå°‘çš„éµ: {missing}")
            if unexpected:
                print(f"    å¤šé¤˜çš„éµ: {unexpected}")
        else:
            print(f"  âœ“ å®Œå…¨åŒ¹é…!")
    except Exception as e:
        print(f"  âœ— éŒ¯èª¤: {e}")
    
    # æ–¹æ¡ˆ 2: ç”¨ ModuleList
    print(f"\næ–¹æ¡ˆ 2: ModuleList (åªæœ‰ç´¢å¼• {sorted(regressor_indices)})")
    try:
        regressor_modules = torch.nn.ModuleList()
        max_idx = max(regressor_indices) if regressor_indices else 0
        
        # æŒ‰ç´¢å¼•å¡«å……
        for i in range(max_idx + 1):
            if i == 0:
                regressor_modules.append(torch.nn.Linear(hidden_size * 2, 64))
            elif i == 1:
                regressor_modules.append(torch.nn.ReLU())
            elif i == 2:
                regressor_modules.append(torch.nn.Dropout(0.2))
            elif i == 3:
                regressor_modules.append(torch.nn.Linear(64, 32))
            elif i == 4:
                regressor_modules.append(torch.nn.ReLU())
            elif i == 5:
                regressor_modules.append(torch.nn.Linear(32, 1))
            else:
                regressor_modules.append(torch.nn.Identity())
        
        # æª¢æŸ¥
        print(f"  âœ“ å»ºç«‹æˆåŠŸ (6 å±¤)")
    except Exception as e:
        print(f"  âœ— éŒ¯èª¤: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    models_dir = Path('models')
    
    if not models_dir.exists():
        print(f"âœ— æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: {models_dir}")
        return
    
    model_files = sorted(models_dir.glob('*_model_v8.pth'))
    print(f"\næ‰¾åˆ° {len(model_files)} å€‹æ¨¡å‹æ–‡ä»¶\n")
    
    if not model_files:
        print("âœ— æ²’æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
        return
    
    # æª¢æŸ¥å‰ 3 å€‹æ¨¡å‹
    for model_file in model_files[:3]:
        checkpoint, lstm_keys, regressor_keys = inspect_checkpoint(model_file)
        if checkpoint:
            test_model_loading(model_file, checkpoint)
    
    # ç¸½çµ
    print(f"\n{'='*80}")
    print("ç¸½çµ")
    print(f"{'='*80}\n")
    
    print("æ ¹æ“šä¸Šé¢çš„æª¢æŸ¥çµæœ:")
    print("\nè«‹æª¢æŸ¥ Regressor å±¤ç´¢å¼•æ˜¯å¦ä¸€è‡´")
    print("å¦‚æœå±¤ç´¢å¼•ä¸æ˜¯ 0, 1, 2, 3, 4, 5 çš„é€£çºŒåºåˆ—")
    print("éœ€è¦ç›¸æ‡‰èª¿æ•´æ¨¡å‹çµæ§‹\n")


if __name__ == '__main__':
    main()
