# ğŸ”§ Advanced Configuration Guide

## ğŸ“‹ ç›®éŒ„

1. [æ¨¡å‹è‡ªè¨‚](#æ¨¡å‹è‡ªè¨‚)
2. [äº¤æ˜“ä¿¡è™Ÿèª¿æ•´](#äº¤æ˜“ä¿¡è™Ÿèª¿æ•´)
3. [æ€§èƒ½å„ªåŒ–](#æ€§èƒ½å„ªåŒ–)
4. [å¤šäº¤æ˜“æ‰€é…ç½®](#å¤šäº¤æ˜“æ‰€é…ç½®)
5. [ç›£æ§å’Œæ—¥èªŒ](#ç›£æ§å’Œæ—¥èªŒ)
6. [éƒ¨ç½²å„ªåŒ–](#éƒ¨ç½²å„ªåŒ–)

## ğŸ¤– æ¨¡å‹è‡ªè¨‚

### ä½¿ç”¨è‡ªè¨‚æ¨¡å‹

å¦‚æœä½ æœ‰è‡ªå·±è¨“ç·´çš„æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥æ”¾åœ¨ HuggingFace:

```python
# bot_predictor.py ä¸­ä¿®æ”¹
HF_REPO = "your_username/your_model_repo"  # ä½ çš„ HuggingFace å€‰åº«
MODEL_PATTERN = "_model_v8.pth"  # ä½ çš„æ¨¡å‹æ–‡ä»¶åæ¨¡å¼
```

### æ¨¡å‹æ¶æ§‹æª¢æ¸¬

è‡ªå‹•æª¢æ¸¬æ”¯æ´çš„ç¶­åº¦:

```python
# bot_predictor.py ä¸­çš„ _detect_model_config() æ–¹æ³•

# æ”¯æ´æª¢æ¸¬:
- input_features (from lstm.weight_ih_l0)
- hidden_size (from lstm weights)
- num_layers (from lstm.weight_hh_l*)
- bidirectional (from lstm.weight_*_reverse)
- output_features (from regressor layers)
```

å¦‚æœæ¨¡å‹ç¶­åº¦æª¢æ¸¬å¤±æ•—ï¼Œæ‰‹å‹•æŒ‡å®š:

```python
# åœ¨ bot_predictor.py ä¸­æ·»åŠ ç‰¹å®šæª¢æŸ¥
def _detect_model_config(self, checkpoint: Dict) -> Dict:
    config = {
        'input_features': 44,     # æ‰‹å‹•è¨­å®š
        'hidden_size': 128,
        'num_layers': 2,
        'output_features': 1,
        'bidirectional': False
    }
    return config
```

## ğŸ’¹ äº¤æ˜“ä¿¡è™Ÿèª¿æ•´

### ä¿®æ”¹é€²å‡ºå ´é‚è¼¯

ç·¨è¼¯ `bot_predictor.py` ä¸­çš„ `_calculate_entry_points()`:

```python
def _calculate_entry_points(
    self,
    current_price: float,
    predicted_prices: List[float],
    trend: str
) -> Tuple[float, float, float]:
    
    if trend == 'UPTREND':
        # è‡ªè¨‚ä¸Šå‡è¶¨å‹¢çš„é€²å‡ºå ´
        entry = min(predicted_prices) * 0.98  # é€²å ´åƒ¹æ ¼
        stop_loss = entry * 0.95  # ä¿®æ”¹: 5% -> 3%
        take_profit = entry * 1.10  # ä¿®æ”¹: 5% -> 10%
    
    elif trend == 'DOWNTREND':
        # è‡ªè¨‚ä¸‹é™è¶¨å‹¢çš„é€²å‡ºå ´
        entry = max(predicted_prices) * 1.02
        stop_loss = entry * 1.05
        take_profit = entry * 0.90
    
    return entry, stop_loss, take_profit
```

### ä¿®æ”¹ä¿¡å¿ƒåº¦è¨ˆç®—

```python
def _analyze_trend(self, ohlcv_data, predicted_prices):
    # å¢åŠ ä¿¡å¿ƒåº¦æ¬Šé‡
    confidence = 0.7  # åŸºç¤
    confidence += momentum * 0.5  # å¾ 0.3 å¢åŠ åˆ° 0.5
    confidence += prediction_accuracy * 0.2  # æ–°å¢é æ¸¬æº–ç¢ºåº¦
    
    return trend, min(0.99, confidence)
```

## âš¡ æ€§èƒ½å„ªåŒ–

### æ¸›å°‘é æ¸¬å»¶é²

```python
# bot_predictor.py
DEFAULT_LOOKBACK = 50  # å¾ 100 æ¸›å°‘åˆ° 50 (2å€åŠ é€Ÿ)

# æˆ–é‡å°ç‰¹å®šå¹£ç¨®
async def _prepare_features(self, ohlcv_data, lookback=50):
    # æ¸›å°‘æ­·å²æ•¸æ“š = æ›´å¿«çš„é æ¸¬
    pass
```

### ä¸¦è¡Œé æ¸¬

```python
# bot.py ä¸­çš„ prediction_loop()

@tasks.loop(minutes=60)
async def prediction_loop():
    # ä¸¦è¡Œè™•ç†æ‰€æœ‰å¹£ç¨®
    tasks = [
        predictor.predict_single(symbol)
        for symbol in list(predictor.models.keys())
    ]
    
    results = await asyncio.gather(*tasks)
    
    # ä¸¦è¡Œ = 20å€‹å¹£ç¨®åŒæ™‚é æ¸¬è€Œä¸æ˜¯é †åº
```

### ç¦ç”¨ä¸éœ€è¦çš„åŠŸèƒ½

```python
# bot.py

# ç¦ç”¨ Web å„€è¡¨æ¿
# (è¨»é‡‹æ‰ dashboard.py çš„å•Ÿå‹•)

# ç¦ç”¨ç‰¹å®šå‘½ä»¤
# @bot.command(name='models')
# async def cmd_list_models(ctx):
#     pass  # è¢«ç¦ç”¨
```

## ğŸŒ å¤šäº¤æ˜“æ‰€é…ç½®

### æ·»åŠ æ–°äº¤æ˜“æ‰€

```python
# bot_predictor.py

EXCHANGES = ['binance', 'bybit', 'okx', 'kraken', 'coinbase']

# æˆ–æŒ‰å„ªå…ˆç´šæ’åº
EXCHANGES = {
    'BTC': ['binance', 'coinbase'],  # BTC ä½¿ç”¨é€™å…©å€‹
    'ALT': ['bybit', 'okx'],          # å…¶ä»–å¹£ç¨®ç”¨é€™å…©å€‹
    'default': ['binance', 'kraken']  # é»˜èªé †åº
}
```

### è‡ªè¨‚äº¤æ˜“æ‰€è¨­ç½®

```python
async def _fetch_ohlcv(self, symbol, timeframe='1h', limit=100):
    for exchange_name in self.exchange_fallback:
        try:
            exchange_config = {
                'rateLimit': 1000,  # è«‹æ±‚é€Ÿç‡é™åˆ¶
                'enableRateLimit': True,
                'timeout': 30000,  # è¶…æ™‚ 30 ç§’
            }
            
            exchange_class = getattr(ccxt, exchange_name)
            exchange = exchange_class(exchange_config)
            
            # ...
        except Exception as e:
            continue
```

## ğŸ“Š ç›£æ§å’Œæ—¥èªŒ

### å•Ÿç”¨è©³ç´°æ—¥èªŒ

```python
# bot.py çš„é–‹å§‹

import logging

logging.basicConfig(
    level=logging.DEBUG,  # å¾ INFO æ”¹ç‚º DEBUG
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot.log'),  # ä¿å­˜åˆ°æ–‡ä»¶
        logging.StreamHandler()  # ä¹Ÿé¡¯ç¤ºåœ¨æ§åˆ¶å°
    ]
)
```

### æ€§èƒ½ç›£æ§

```python
# åœ¨ bot_predictor.py ä¸­æ·»åŠ 

import time

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
    
    def record(self, key: str, duration: float):
        if key not in self.metrics:
            self.metrics[key] = []
        self.metrics[key].append(duration)
    
    def report(self):
        for key, durations in self.metrics.items():
            avg = sum(durations) / len(durations)
            max_time = max(durations)
            print(f"{key}: avg={avg:.2f}ms, max={max_time:.2f}ms")

monitor = PerformanceMonitor()

# ä½¿ç”¨
start = time.time()
result = await predictor.predict_single(symbol)
monitor.record(f"predict_{symbol}", (time.time() - start) * 1000)
```

### éŒ¯èª¤è¿½è¹¤

```python
# é›†ä¸­éŒ¯èª¤è™•ç†

class ErrorHandler:
    def __init__(self):
        self.errors = {}
    
    def log_error(self, error_type: str, error: Exception):
        if error_type not in self.errors:
            self.errors[error_type] = []
        self.errors[error_type].append({
            'time': datetime.utcnow(),
            'message': str(error)
        })
    
    def get_summary(self):
        return {key: len(v) for key, v in self.errors.items()}
```

## ğŸš€ éƒ¨ç½²å„ªåŒ–

### Docker è³‡æºé™åˆ¶

```yaml
# docker-compose.yml

services:
  crypto-bot:
    # ...
    deploy:
      resources:
        limits:
          cpus: '1'  # é™åˆ¶ 1 CPU
          memory: 2G  # é™åˆ¶ 2GB å…§å­˜
        reservations:
          cpus: '0.5'
          memory: 1G
```

### Kubernetes éƒ¨ç½²

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crypto-bot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: crypto-bot
  template:
    metadata:
      labels:
        app: crypto-bot
    spec:
      containers:
      - name: crypto-bot
        image: crypto-bot:latest
        env:
        - name: DISCORD_TOKEN
          valueFrom:
            secretKeyRef:
              name: discord-secret
              key: token
        resources:
          limits:
            cpu: 1
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          exec:
            command:
            - python
            - -c
            - "import torch; print('OK')"
          initialDelaySeconds: 30
          periodSeconds: 10
```

### é›¶åœæ©Ÿéƒ¨ç½²

```bash
#!/bin/bash

# æ–°å»ºç«‹å‰¯æœ¬
docker-compose up -d crypto-bot-v2

# ç­‰å¾…æº–å‚™å°±ç·’
sleep 30

# æª¢æŸ¥å¥åº·ç‹€æ…‹
if docker-compose exec -T crypto-bot-v2 python bot.py --health-check; then
    # åœæ­¢èˆŠç‰ˆæœ¬
    docker-compose down crypto-bot
    # é‡å‘½åæ–°ç‰ˆæœ¬
    docker-compose rename crypto-bot-v2 crypto-bot
else
    # å›æ»¾
    docker-compose down crypto-bot-v2
fi
```

## ğŸ” å®‰å…¨æ€§å¼·åŒ–

### å¯†é‘°ç®¡ç†

```python
# ä½¿ç”¨ç’°å¢ƒè®Šé‡è€Œä¸æ˜¯ç¡¬ç·¨ç¢¼
import os
from dotenv import load_dotenv

load_dotenv()

DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
if not DISCORD_TOKEN:
    raise ValueError("DISCORD_TOKEN must be set")
```

### API é€Ÿç‡é™åˆ¶

```python
from functools import wraps
import asyncio

def rate_limit(calls_per_second: int):
    min_interval = 1 / calls_per_second
    last_called = [0]
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            elapsed = asyncio.get_event_loop().time() - last_called[0]
            if elapsed < min_interval:
                await asyncio.sleep(min_interval - elapsed)
            last_called[0] = asyncio.get_event_loop().time()
            return await func(*args, **kwargs)
        return wrapper
    return decorator

@rate_limit(calls_per_second=10)
async def predict_single(self, symbol: str):
    # ...
    pass
```

## ğŸ“ˆ æŒ‡æ¨™å’Œå‘Šè­¦

### Prometheus é›†æˆ

```python
from prometheus_client import Counter, Histogram, Gauge

# å®šç¾©æŒ‡æ¨™
prediction_total = Counter(
    'predictions_total',
    'Total predictions made',
    ['symbol', 'trend']
)

prediction_duration = Histogram(
    'prediction_duration_seconds',
    'Prediction duration',
    ['symbol']
)

models_loaded = Gauge(
    'models_loaded',
    'Number of loaded models'
)

# ä½¿ç”¨
with prediction_duration.labels(symbol=symbol).time():
    result = await predictor.predict_single(symbol)

prediction_total.labels(symbol=symbol, trend=result['trend']).inc()
models_loaded.set(len(predictor.models))
```

## ğŸ”„ è‡ªå‹•æ›´æ–°

### æª¢æŸ¥æ–°æ¨¡å‹

```python
@tasks.loop(hours=1)  # æ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡
async def check_for_new_models():
    try:
        current_files = set(predictor.model_info.keys())
        new_files = await predictor._get_hf_model_files()
        new_symbols = {predictor._extract_symbol(f) for f in new_files}
        
        added = new_symbols - current_files
        if added:
            logger.info(f"Found new models: {added}")
            for symbol in added:
                await predictor._load_model(symbol, f"{symbol}{MODEL_PATTERN}")
    except Exception as e:
        logger.error(f"Error checking for new models: {e}")
```

---

**æç¤º**: æ‰€æœ‰é€™äº›å„ªåŒ–éƒ½æ˜¯å¯é¸çš„ã€‚é–‹å§‹æ™‚ä½¿ç”¨é»˜èªè¨­ç½®ï¼Œç„¶å¾Œæ ¹æ“šéœ€è¦é€²è¡Œèª¿æ•´ã€‚
